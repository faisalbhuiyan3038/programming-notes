# AI Customer Support

## Resources:

Videos:
https://www.loom.com/share/f2447d8e9083479599c2d0248af77bf2?start-embed-anon-signup=true

https://www.loom.com/share/566bb663f5b54defab5b0493d8549eea?start-embed-anon-signup=true

- https://medium.com/@billzhangsc/building-an-ai-powered-support-assistant-with-next-js-and-openai-3c2c8e18cd4c
- https://www.loom.com/share/03b87bb24f9f462d8353807211f7c4a1
- https://www.loom.com/share/75af4269ab66450e943160c199895aa7 - RAG Tutorial with OpenAI, LongChain and Pinecone
- https://openrouter.ai/models/meta-llama/llama-3.1-8b-instruct:free - Free API to access the LLama 3.1 LLM
- https://www.youtube.com/watch?v=emS9QL5EmXk - Chatgpt API setup in NodeJS
- https://www.youtube.com/watch?v=nQdyiK7-VlQ - How to deploy a NodeJS app with AWS EC2
- https://www.youtube.com/watch?v=nSQrY-uPWLY - Amazon bedrock API tutorial
- https://www.youtube.com/watch?v=xdr5ByCpnd4 - LongChain openai vector embeddings for beginners
- https://www.youtube.com/watch?v=Y08Nn23o_mY - Intro to RAG for AI (Retrieval Augmented Generation)
- https://www.youtube.com/watch?v=Ylz779Op9Pw - How to improve LLMS with RAG
- https://www.youtube.com/watch?v=EhlPDL4QrWY - Build and deploy a RAG app with Pinecone

### Tasks

- Level 1: Create a basic chatbot with hard coded responses

- Level 2: Respond to the user intelligently using any Gen-AI model

- Level 3: Deploy your web-app to AWS EC2 Servers

- Level 3.5: Respond to the user with LLMs through the AWS Bedrock API

- Level 4: Implement RAG so the chatbot responds based on a given knowledge base

- Level 4.5: Create an LLM orchestration pattern with a router and task specific models

- Bonus: Add multi-language support to cater to a diverse customer base

- Bonus: Add user authentication to personalize the chat experience

- Bonus: Implement a feedback mechanism for users to rate the chatbot's responses
